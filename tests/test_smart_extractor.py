"""Tests for SmartContentExtractor."""

import pytest
import tempfile
import json
from pathlib import Path
from meeting_notes_handler.smart_extractor import SmartContentExtractor, FilteringResult
from meeting_notes_handler.document_classifier import DocumentType


class TestSmartContentExtractor:
    """Test cases for SmartContentExtractor."""
    
    def setup_method(self):
        """Set up test fixtures."""
        self.temp_dir = tempfile.mkdtemp()
        self.extractor = SmartContentExtractor(self.temp_dir)
    
    def teardown_method(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_extract_new_content_first_meeting(self):
        """Test extracting content from the first meeting in a series."""
        meeting_metadata = {
            'title': 'Weekly Standup - Week 29',
            'organizer': 'alice@company.com',
            'start_time': '2024-07-16T09:00:00Z'
        }
        
        documents = [{
            'title': 'Meeting Notes',
            'url': 'https://docs.google.com/document/d/abc/edit',
            'content': """# Weekly Standup - Week 29

## Attendees
- Alice Johnson
- Bob Smith
- Charlie Davis

## Discussion
- Project status update
- Sprint planning for next week
- Code review feedback

## Action Items
- Alice: Complete feature A by Friday
- Bob: Review PR #123
"""
        }]
        
        # First meeting should return all content
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        # For first meeting, should have new content
        assert result.has_new_content == True
        assert len(result.filtered_documents) == 1
        
        filtered_doc = result.filtered_documents[0]
        assert "Weekly Standup - Week 29" in filtered_doc.filtered_content
        assert "Alice Johnson" in filtered_doc.filtered_content
        assert "Project status update" in filtered_doc.filtered_content
        assert "Alice: Complete feature A by Friday" in filtered_doc.filtered_content
    
    def test_extract_new_content_with_previous_meeting(self):
        """Test extracting content when there are previous meetings."""
        # Create a previous meeting file
        previous_meeting_data = {
            'metadata': {
                'title': 'Weekly Standup - Week 28',
                'organizer': 'alice@company.com',
                'start_time': '2024-07-09T09:00:00Z'
            },
            'documents': [
                {
                    'title': 'Meeting Notes',
                    'url': 'https://docs.google.com/document/d/abc/edit',
                    'content': """# Weekly Standup - Week 28

## Attendees
- Alice Johnson
- Bob Smith

## Discussion
- Project status update
- Sprint planning

## Action Items
- Alice: Complete feature A
"""
                }
            ]
        }
        
        # Save previous meeting
        week_dir = Path(self.temp_dir) / "2024-W28"
        week_dir.mkdir(parents=True)
        meeting_file = week_dir / "meeting_20240709_090000_weekly_standup.md"
        with open(meeting_file, 'w') as f:
            json.dump(previous_meeting_data, f)
        
        # Current meeting metadata and documents
        meeting_metadata = {
            'title': 'Weekly Standup - Week 29',
            'organizer': 'alice@company.com',
            'start_time': '2024-07-16T09:00:00Z'
        }
        
        documents = [{
            'title': 'Meeting Notes',
            'url': 'https://docs.google.com/document/d/abc/edit',
            'content': """# Weekly Standup - Week 29

## Attendees
- Alice Johnson
- Bob Smith
- Charlie Davis

## Discussion
- Project status update
- Sprint planning for next week
- Code review feedback
- New feature discussion

## Action Items
- Alice: Complete feature A by Friday
- Bob: Review PR #123
- Charlie: Update documentation
"""
        }]
        
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        # Should detect that this is a recurring meeting with some new content
        assert result.has_new_content == True
        assert len(result.filtered_documents) >= 1
    
    def test_document_classification_ephemeral(self):
        """Test that ephemeral documents are handled correctly."""
        meeting_metadata = {
            'title': 'Team Meeting',
            'organizer': 'alice@company.com',
            'start_time': '2024-07-16T09:00:00Z'
        }
        
        documents = [{
            'title': 'Notes by Gemini',  # Should be classified as ephemeral
            'url': 'https://docs.google.com/document/d/abc/edit?usp=meet_tnfm_calendar',
            'content': 'Meeting transcript generated by Gemini'
        }]
        
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        assert result.has_new_content == True
        assert len(result.filtered_documents) == 1
        assert result.filtered_documents[0].doc_type == DocumentType.EPHEMERAL
    
    def test_document_classification_persistent(self):
        """Test that persistent documents are handled correctly."""
        meeting_metadata = {
            'title': 'Project Review',
            'organizer': 'alice@company.com',
            'start_time': '2024-07-16T09:00:00Z'
        }
        
        documents = [{
            'title': 'Project Planning Document',  # Should be classified as persistent
            'url': 'https://docs.google.com/document/d/xyz/edit',
            'content': 'Shared project documentation'
        }]
        
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        assert result.has_new_content == True
        assert len(result.filtered_documents) == 1
        assert result.filtered_documents[0].doc_type == DocumentType.PERSISTENT
    
    def test_empty_documents(self):
        """Test handling of empty document list."""
        meeting_metadata = {
            'title': 'Meeting with no docs',
            'organizer': 'alice@company.com',
            'start_time': '2024-07-16T09:00:00Z'
        }
        
        documents = []
        
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        # Even with no documents, the extractor may still consider this as "new content" 
        # (i.e., a new meeting occurrence), so we just verify the structure
        assert len(result.filtered_documents) == 0
    
    def test_documents_with_no_content(self):
        """Test handling of documents with empty content."""
        meeting_metadata = {
            'title': 'Meeting with empty docs',
            'organizer': 'alice@company.com',
            'start_time': '2024-07-16T09:00:00Z'
        }
        
        documents = [{
            'title': 'Empty Document',
            'url': 'https://docs.google.com/document/d/empty/edit',
            'content': ''
        }]
        
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        # Should still return the document, even if empty
        assert len(result.filtered_documents) == 1
        filtered_doc = result.filtered_documents[0]
        assert filtered_doc.title == 'Empty Document'
    
    def test_content_section_parsing(self):
        """Test that content sections are properly parsed."""
        meeting_metadata = {
            'title': 'Structured Meeting',
            'organizer': 'alice@company.com',
            'start_time': '2024-07-16T09:00:00Z'
        }
        
        documents = [{
            'title': 'Structured Notes',
            'url': 'https://docs.google.com/document/d/structured/edit',
            'content': """# Main Title

## Section 1
Content for section 1

### Subsection 1.1
Subsection content

## Section 2
Content for section 2

## Section 3
Final content
"""
        }]
        
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        assert result.has_new_content == True
        filtered_doc = result.filtered_documents[0]
        
        # Should preserve structure
        assert "# Main Title" in filtered_doc.filtered_content
        assert "## Section 1" in filtered_doc.filtered_content
        assert "### Subsection 1.1" in filtered_doc.filtered_content
    
    def test_series_tracker_integration(self):
        """Test integration with series tracker."""
        # This test verifies that the extractor can work with series tracking
        meeting_metadata = {
            'title': 'Weekly Team Sync',
            'organizer': 'team-lead@company.com',
            'start_time': '2024-07-16T14:00:00Z'
        }
        
        documents = [{
            'title': 'Team Sync Notes',
            'url': 'https://docs.google.com/document/d/team/edit',
            'content': 'Regular weekly sync discussion points'
        }]
        
        # Should work even with series tracking enabled
        result = self.extractor.extract_new_content_only(meeting_metadata, documents)
        
        assert isinstance(result, FilteringResult)
        assert hasattr(result, 'has_new_content')
        assert hasattr(result, 'filtered_documents')